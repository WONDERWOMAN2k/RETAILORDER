# -*- coding: utf-8 -*-
"""newretailorder.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14UnfkHQnLyZAu5NrGzndIZxseLlrxFL3
"""

import os

# Ensure the .kaggle directory exists
os.makedirs(os.path.expanduser("~/.kaggle"), exist_ok=True)

# Rename the uploaded kaggle.json to the correct location
os.rename("kaggle.json", os.path.expanduser("~/.kaggle/kaggle.json"))

# Verify if the file is in the correct location
print("Kaggle API key successfully placed at:", os.path.expanduser("~/.kaggle/kaggle.json"))

import os

extracted_files = os.listdir(download_path)
print(f"Files extracted: {extracted_files}")

df = pd.read_csv(csv_file_path, encoding="ISO-8859-1")
df.head()

df.fillna(0, inplace=True)  # Replace missing values with 0
df.columns = df.columns.str.lower().str.replace(' ', '_')  # Standardize column names
df.rename(columns={'order id': 'order_id', 'sale price': 'sale_price'}, inplace=True)
df["sale_price"] = df["list_price"] * (1 - df["discount_percent"] / 100)

config = {
    "host": "gateway01.us-west-2.prod.aws.tidbcloud.com",
    "port": 4000,
    "user": "2cG3MBTK8AjfDHM.root",  # Your username
    "password": "dYaKCArJUfrmgU85",  # Your password
    "database": "retailorder",  # Your database
    "ssl_ca": "/content/drive/My Drive/Colab Notebooks/isrgrootx1.pem",  # SSL certificate path
    "ssl_verify_cert": True,  # Enforce certificate verification
    "ssl_disabled": False  # Ensure secure connection
}

from google.colab import files
files.upload()  # Upload the certificate file

import mysql.connector
import pandas as pd

# Define TiDB Cloud configuration
config = {
   "host": "gateway01.us-west-2.prod.aws.tidbcloud.com",
    "port": 4000,
    "user": "2cG3MBTK8AjfDHM.root",  # Your username
    "password": "dYaKCArJUfrmgU85",  # Your password
    "database": "retailorder",  # Database name
    "ssl_ca": "/content/isrgrootx1.pem",  # Path to the SSL certificate (adjust for your environment)
    "ssl_verify_cert": True,  # Enforce certificate verification
    "ssl_disabled": False  # Ensure secure connection
}

# Read and clean the dataset (assuming dataset is already downloaded and extracted)
df = pd.read_csv("orders.csv", encoding="ISO-8859-1")
df.fillna(0, inplace=True)
df.columns = df.columns.str.lower().str.replace(' ', '_')
df.rename(columns={'order id': 'order_id', 'sale price': 'sale_price'}, inplace=True)
df["sale_price"] = df["list_price"] * (1 - df["discount_percent"] / 100)

# Print dataset columns to verify correct mapping
print("Dataset Columns:", df.columns)

# Initialize connection and cursor only if the connection is successful
connection = None
cursor = None

# Connect to TiDB Cloud and create the table
try:
    connection = mysql.connector.connect(**config)  # Create the connection
    cursor = connection.cursor()  # Initialize the cursor

    # Create table in TiDB Cloud
    create_table_query = """
    CREATE TABLE IF NOT EXISTS orders (
        order_id INT PRIMARY KEY,
        order_date DATE,
        ship_mode VARCHAR(255),
        segment VARCHAR(255),
        country VARCHAR(255),
        city VARCHAR(255),
        state VARCHAR(255),
        postal_code VARCHAR(20),
        region VARCHAR(255),
        category VARCHAR(255),
        sub_category VARCHAR(255),
        product_id VARCHAR(255),
        cost_price FLOAT,
        list_price FLOAT,
        quantity INT,
        discount_percent FLOAT
    );
    """
    cursor.execute(create_table_query)  # Execute table creation query
    connection.commit()  # Commit the transaction
    print("âœ… Orders table created successfully!")

    # Insert data into the database
    insert_query = """
    INSERT INTO orders (order_id, order_date, ship_mode, segment, country, city, state, postal_code, region, category, sub_category, product_id, cost_price, list_price, quantity, discount_percent)
    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
    """

    for index, row in df.iterrows():
        values = (
            row['order_id'], row['order_date'], row['ship_mode'], row['segment'], row['country'],
            row['city'], row['state'], row['postal_code'], row['region'], row['category'],
            row['sub_category'], row['product_id'], row['cost_price'], row['list_price'],
            row['quantity'], row['discount_percent']
        )
        cursor.execute(insert_query, values)  # Insert row into the database
    connection.commit()  # Commit all inserts

    # Check the total number of orders
    cursor.execute("SELECT COUNT(*) FROM orders;")
    result = cursor.fetchone()
    print("Total Orders:", result[0])

except mysql.connector.Error as err:
    print(f"Error: {err}")

finally:
    if connection and connection.is_connected():
        cursor.close()  # Close the cursor
        connection.close()  # Close the database connection
        print("Connection closed.")

print(df.head())
# Check for rows where order_id is null or invalid
print("Rows with null order_id:", df[df['order_id'].isnull()])
print("Rows with invalid order_id:", df[~df['order_id'].apply(lambda x: isinstance(x, (int, float)))])
# Remove rows with NaN order_id
df.dropna(subset=['order_id'], inplace=True)

# Optionally, replace invalid order_id with a placeholder value (if needed)
df['order_id'] = pd.to_numeric(df['order_id'], errors='coerce')  # Convert to numeric, invalid become NaN
df.dropna(subset=['order_id'], inplace=True)  # Drop rows where order_id is still NaN

from google.colab import files
files.upload()  # Upload the isrgrootx1.pem file from your local system

# Define TiDB Cloud configuration
config = {
   "host": "gateway01.us-west-2.prod.aws.tidbcloud.com",
    "port": 4000,
    "user": "2cG3MBTK8AjfDHM.root",  # Your username
    "password": "dYaKCArJUfrmgU85",  # Your password
    "database": "retailorder",  # Database name
    "ssl_ca": "/content/isrgrootx1.pem",  # Path to the SSL certificate (adjust for your environment)
    "ssl_verify_cert": True,  # Enforce certificate verification
    "ssl_disabled": False  # Ensure secure connection
}